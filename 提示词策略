提示词策略
什么是提示工程？
提示是一个文本输入，它指导LLM生成文本输出。
提示工程是设计有效提示的过程，以从LLMs中引发高质量和相关的输出。提示工程需要创造力、对LLM的理解和精确度。提示（prompt）成为LLM-驱动应用程序成功的关键要素之一。因此，在这一步投入时间和资源至关重要，接下来我们将讨论一些最佳实践和原则。
提示工程原理
一般来说，由于需要考虑的变量太多（使用的模型类型、应用目标、支持的基础设施等），因此没有获得“完美”提示的固定规则。尽管如此，有一些明确的原理，如果将其纳入提示中，已被证明会产生积极的效果。让我们来探讨一些这些原理。
清晰的说明
明确指令的原则是向模型提供足够的信息和指导，以便正确且高效地完成任务。清晰的指令应包括以下要素：
任务的目标或目标，例如“写一首诗”或“总结一篇文章”
预期输出格式或结构，例如：“使用四行押韵词”或“使用每点不超过 10 个单词的列表”
任务约束或限制，例如“不要使用任何粗俗语言”或“不要复制任何源文本”
任务的内容或背景，例如“这首诗是关于秋天的”或“这篇文章来自科学期刊”
然而，有时仅仅清晰度是不够的。我们可能需要推断LLM的思维方式，使其在任务上更加稳健。
将复杂任务分解为子任务
如前所述，提示工程是一种设计有效输入以执行各种任务的技术。有时，任务过于复杂或模糊，无法由单个提示处理，因此最好将它们拆分为更简单的子任务，由不同的提示来解决。
以下是一些将复杂任务分解为子任务的示例：
文本摘要：一个复杂的任务，涉及生成长文本的简洁且准确的摘要。这个任务可以分为以下子任务：
提取文本中的要点或关键词
重写主要观点或关键词，使其表达连贯且流畅
裁剪摘要以适应所需的长度或格式
机器翻译：一个复杂的任务，涉及将文本从一种语言翻译成另一种语言。这个任务可以分为以下子任务：
检测文本的源语言
将文本转换为中间表示形式，以保留原文的意义和结构
生成目标语言的文本，从中间表示形式中
诗歌生成：一项涉及创作遵循特定风格、主题或情感的诗歌的创造性任务。此任务可以分为以下子任务：
选择诗歌形式（如十四行诗、俳句、雷姆里克等）以及押韵模式（如 ABAB、AABB、ABCB 等）为诗歌
生成一首诗的标题和主题，基于用户的输入或偏好
生成符合所选形式、韵律和主题的诗句或诗节
精炼和润色诗歌，以确保其连贯性、流畅性和原创性
代码生成：一项涉及生成执行特定功能或任务的代码片段的技术任务。此任务可以分为以下子任务：
选择编程语言（如 Python、Java、C++等）以及代码的框架或库（如 TensorFlow、PyTorch、React 等）
生成基于用户输入或指定的函数名称、参数列表和返回值列表
生成实现代码逻辑和功能的函数主体
添加注释和文档以解释代码及其用法
在一个多样化的环境中，了解同一个系统消息可能在不同模型中效率不同至关重要。例如，与 GPT-4 完美匹配的系统消息在应用于 Llama 2 时可能效率不高。因此，根据您为应用程序选择的具体类型设计提示至关重要。
请求论证
LLMs 是这样构建的，它们根据前面的标记预测下一个标记，而不回顾它们的生成。这可能导致模型以非常令人信服的方式向用户输出错误的内容。如果由 LLM 驱动的应用程序没有提供对该响应的具体参考，那么验证其背后的真实情况可能很困难。因此，在提示中指定支持 LLM 的答案，并提供一些反思和论证，可以促使模型从其行为中恢复过来。
生成许多输出，然后使用模型选择最佳的一个
LLMs 是这样构建的，它们根据前面的标记来预测下一个标记，而不会回顾它们的生成。如果这种情况发生，如果一个采样的标记是错误的（换句话说，如果模型运气不好），LLM 将会继续生成错误的标记，从而产生错误的内容。
一种克服这种限制的方法是扩大选择正确标记的概率空间。我们不是只生成一个响应，而是可以提示模型生成多个响应，然后选择最适合用户查询的那个。这把任务分成了两个子任务，对于我们的LLM：
1.生成对用户查询的多个响应
2.比较这些响应并选择最佳答案，根据我们可以在元提示中指定的某些标准
重复指令于结尾
近期偏差是指LLMs倾向于给予提示中出现在末尾的信息更多权重，而忽略或忘记之前出现的信息。这可能导致不准确或不一致的响应，没有考虑到整个任务的上下文。例如，如果提示是两个人之间的长对话，模型可能只关注最后几条消息，而忽略之前的消息。
让我们看看一些克服近期偏差的方法
一种克服近期偏差的可能方法是将任务分解成更小的步骤或子任务，并在过程中提供反馈或指导。这有助于模型专注于每个步骤，避免陷入无关紧要的细节。
另一种通过提示工程技巧克服近期偏差的方法是在提示末尾重复指令或任务的主要目标。这有助于提醒模型它应该做什么以及应该生成什么类型的响应。
使用分隔符
这有助于我们的LLM更好地理解其意图，以及将不同的章节和段落相互关联。
分隔符可以是任何字符或符号的序列。
这导致一系列好处，包括：
清晰分隔：分隔符在提示中标记不同的部分，分隔指令、示例和期望的输出。
指导LLMs：正确使用分隔符可以消除歧义，有效地引导模型。
增强精度：分隔符提高提示理解，从而产生更相关的响应。
改进连贯性：有效使用分隔符组织指令、输入和输出，从而产生连贯的响应。
进阶技术
Few-shot
即向模型提供我们希望其如何响应的示例，这是一种强大的技术，可以在不干扰整体架构的情况下实现模型定制。
思维链
思维链（CoT）是一种通过中间推理步骤实现复杂推理能力的技巧。它还鼓励模型解释其推理过程，“迫使”它不要过于迅速，以免给出错误答案。

